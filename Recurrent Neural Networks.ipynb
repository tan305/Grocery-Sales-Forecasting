{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "from datetime import date, timedelta\n",
    "from torch import nn,optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a gpu is available, set gpu else cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Transform the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = '2017-07-15'\n",
    "def read_process_data(drop_cols):\n",
    "    df = pd.read_csv('lag.csv',parse_dates=['date'])\n",
    "    df = df[df['date'] > '2017-6-15']\n",
    "    df.sort_values(by=['date','store_nbr','family'],inplace=True)\n",
    "    df.reset_index(drop = True,inplace = True)\n",
    "    df.drop(drop_cols,axis=1,inplace=True)\n",
    "    df = create_dummies(df,['store_nbr','family'])\n",
    "    month = df[df['date'] >= split].to_numpy()\n",
    "    X_train,y_train,X_test,y_test = data_split(df)\n",
    "    del df\n",
    "    gc.collect()\n",
    "    X_train,y_train,X_test,y_test = data_prep(X_train,y_train,X_test,y_test)\n",
    "    train_iter,test_iter = loader(X_train,y_train,X_test,y_test)\n",
    "    return train_iter,test_iter,y_test,month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined a function to plot predicted values vs actual values\n",
    "def plot_prediction(tens):\n",
    "    #month = data['date'][split:].to_numpy()\n",
    "\n",
    "    plt.figure(figsize = (18,6))\n",
    "    plt.plot(month,y_test)\n",
    "    plt.plot(month,tens.cpu().numpy()[:,-1])\n",
    "    plt.legend(['Actual Values', 'Predicted Values'], loc='upper left')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Unit Sales\")\n",
    "    plt.title(\"Unit Sales vs Year\")\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(plticker.MultipleLocator(base=15.0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comp(mse_lst,time_lst):\n",
    "    fig, ax1 = plt.subplots(figsize = (18,6))\n",
    "\n",
    "    ax1.set_xlabel('Model Number')\n",
    "    ax1.set_ylabel('MSE',color='tab:red')\n",
    "    ax1.plot(list(range(0,len(mse_lst))),np.array(mse_lst), color='tab:red')\n",
    "\n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    ax2.set_ylabel('Time (in ms)',color='tab:blue')  # we already handled the x-label with ax1\n",
    "    ax2.plot(list(range(0,len(mse_lst))),np.array(time_lst), color='tab:blue')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(data,col_list):\n",
    "    \n",
    "    for col_name in col_list:\n",
    "        \n",
    "        drop_first = False\n",
    "        if len(data[col_name].value_counts().index) == 2:\n",
    "            drop_first = True\n",
    "            \n",
    "        tempdf = pd.get_dummies(data[col_name],drop_first = drop_first)\n",
    "        \n",
    "        if not drop_first:\n",
    "            tempdf.columns = [col_name +'_' + str(col) for col in tempdf.columns]\n",
    "        else:\n",
    "            tempdf.columns = [col_name]\n",
    "            \n",
    "        data = data.drop(col_name,axis = 1).join(tempdf)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    # Split data into training and testing sets\n",
    "    data_train = data[data['date'] < split]\n",
    "    data_test  = data[data['date'] >= split]\n",
    "\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    \n",
    "    mm = min_max_scaler.fit(data_train.drop('date',axis = 1))\n",
    "    data_train = pd.DataFrame(mm.transform(data_train.drop('date',axis = 1)),columns=data_train.drop('date',axis = 1).columns, index=data_train.drop('date',axis = 1).index)\n",
    "    data_test  = pd.DataFrame(mm.transform(data_test.drop('date',axis = 1)),columns=data_test.drop('date',axis = 1).columns, index=data_test.drop('date',axis = 1).index)\n",
    "    \n",
    "    # Split data into dependent and independent variables\n",
    "    X_train = data_train.drop(['unit_sales'],axis = 1).to_numpy()\n",
    "    y_train = data_train['unit_sales'].to_numpy()\n",
    "    X_test  = data_test.drop(['unit_sales'],axis = 1).to_numpy()\n",
    "    y_test  = data_test['unit_sales'].to_numpy()\n",
    "    \n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "# Defined a function to convert numpy arrays into tensors\n",
    "def data_prep(X_train,y_train,X_test,y_test):\n",
    "    \n",
    "    # Convert numpy arrays into tensors\n",
    "    X_train = torch.tensor(X_train).float()\n",
    "    y_train = torch.tensor(y_train).view(-1, 1).float()\n",
    "\n",
    "    X_test = torch.tensor(X_test).float()\n",
    "    y_test = torch.tensor(y_test).view(-1, 1).float()\n",
    "\n",
    "    return X_train,y_train,X_test,y_test\n",
    "    \n",
    "\n",
    "def loader(X_train,y_train,X_test,y_test):\n",
    "    # Build a data loader object from the two tensors for training data\n",
    "    train_datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_iter = torch.utils.data.DataLoader(train_datasets, batch_size=round(len(X_train)/226), shuffle=False)\n",
    "\n",
    "    # Build a data loader object from the two tensors for testing data\n",
    "    test_datasets = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    test_iter = torch.utils.data.DataLoader(test_datasets, batch_size=round(len(X_test)), shuffle=False)\n",
    "    \n",
    "    return train_iter,test_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Oil Price','unit_sales (t-1)','unit_sales (t-2)','unit_sales (t-3)','unit_sales (t-4)',\n",
    "            'unit_sales (t-5)','unit_sales (t-6)','unit_sales (t-7)','unit_sales (t-8)','unit_sales (t-9)',\n",
    "            'unit_sales (t-10)','unit_sales (t-11)','unit_sales (t-12)','Oil Price (t-1)','Oil Price (t-2)',\n",
    "            'Oil Price (t-3)','Oil Price (t-4)','Oil Price (t-5)','Oil Price (t-6)','Oil Price (t-7)',\n",
    "            'Oil Price (t-8)','Oil Price (t-9)','Oil Price (t-10)','Oil Price (t-11)','Oil Price (t-12)']\n",
    "\n",
    "train_iter,test_iter,y_test,month = read_process_data(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDefine a class for the RNN model\n",
    "class RecurrentModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size,num_layers=1):\n",
    "        super().__init__()\n",
    "        # Initialize attributes used by the model\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define an RNN layer\n",
    "        self.rnn = nn.RNN(self.input_size, self.hidden_size,num_layers = self.num_layers)\n",
    "    \n",
    "    # Define a method to set the hidden state at the beginning of every epoch\n",
    "    def hidden_reset(self):\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_size),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the sequence of operation and pass the input tensor through each operation\n",
    "        x,_ = self.rnn(x.view(len(x), self.batch_size, -1))\n",
    "        \n",
    "        return x[:,:,-1][:,-1].view(len(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the validation MSE\n",
    "def test(model):\n",
    "    # Use no_grad to allow us to perform regular Python operations on tensors, independent of PyTorchâ€™s computation graph\n",
    "    with torch.no_grad():\n",
    "        # Loop through the test data\n",
    "        for inputs, labels in test_iter:\n",
    "            # Move the tensors to the device selected above (GPU or CPU)\n",
    "            #inputs = inputs.to(device)\n",
    "            #labels = labels.to(device)\n",
    "            # Enter model evaluation mode\n",
    "            model.to('cpu')\n",
    "            model.eval()\n",
    "            # Make predictions on the validation dataset\n",
    "            y_pred = model(inputs)\n",
    "            # Calculate the mean squared error for the predictions\n",
    "            loss = lossfunc(y_pred, labels)\n",
    "    \n",
    "    # Return MSE and prediction values\n",
    "    return loss.item(),y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialze the loss function as Mean Square Error loss\n",
    "lossfunc = nn.MSELoss()\n",
    "\n",
    "#Define a function to train the model\n",
    "def train(model, num_epochs = 200,recurr = False):\n",
    "    # Initialize the optimizer as Stochastic Gradient Descent and initialize the learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    i=0\n",
    "    # Loop over the epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Check if the model being passed in is a recurrent neural network\n",
    "        if recurr == True:\n",
    "            model.hidden = model.hidden_reset()\n",
    "        # Loop through each batch in the training dataset\n",
    "        for inputs, labels in train_iter:\n",
    "            # Move the tensors to the device selected above (GPU or CPU)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Call the model to perform the forward computation\n",
    "            outputs = model(inputs)\n",
    "            # Compute the loss given our outputs and labels\n",
    "            loss = lossfunc(outputs, labels)\n",
    "            # Since Gradients are accumulated, we have to zero them\n",
    "            optimizer.zero_grad()\n",
    "            # Compute Gradients using backpropogation\n",
    "            loss.backward()\n",
    "            # Update weights based on the current gradient\n",
    "            optimizer.step()\n",
    "        i += 1\n",
    "        print(i)\n",
    "\n",
    "    # Store the final validation and training loss\n",
    "    test_mse,y_pred = test(model)\n",
    "    mse = loss.item()\n",
    "            \n",
    "    return mse,test_mse,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model i:5,j:2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "Model i:5,j:3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "Model i:18,j:2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-827b48745d4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRecurrentModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m88\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mrnn_mse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrnnt_mse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrnny_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mrnn_mse_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn_mse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mrnnt_mse_lst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnnt_mse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-bf52f7f7cb4d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, num_epochs, recurr)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m# Compute Gradients using backpropogation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[1;31m# Update weights based on the current gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn_mse_lst = []\n",
    "rnnt_mse_lst = []\n",
    "rnny_pred_lst = []\n",
    "rnn_time = []\n",
    "for i in [5,18]:\n",
    "    for j in [2,3]:\n",
    "        print(f\"Model i:{i},j:{j}\")\n",
    "        # Initialize objects to track execution time\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        # Begin recording execution time\n",
    "        start.record()\n",
    "        # Initialize model\n",
    "        model = RecurrentModel(input_size = 1, hidden_size = i, batch_size = 88,num_layers=j)\n",
    "        model.to(device)\n",
    "        rnn_mse,rnnt_mse,rnny_pred = train(model,60,True)\n",
    "        rnn_mse_lst.append(rnn_mse)\n",
    "        rnnt_mse_lst.append(rnnt_mse)\n",
    "        rnny_pred_lst.append(rnny_pred)\n",
    "        # Stop recording execution time\n",
    "        end.record()\n",
    "        # Wait for kernels in all streams of a cuda device to complete\n",
    "        torch.cuda.synchronize()\n",
    "        # Compute and store execution time\n",
    "        rnn_time.append(start.elapsed_time(end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comp(rnnt_mse_lst,rnn_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_rnn = rnnt_mse_lst.index(min(rnnt_mse_lst))\n",
    "print(f\"The best training mean squared error for Backpropogation through time is: {rnn_mse_lst[best_model_rnn]}\")\n",
    "print(f\"The best validation mean squared error for Backpropogation through time is: {rnnt_mse_lst[best_model_rnn]}\")\n",
    "print(f\"The best computational effort for Backpropogation through time in milliseconds is: {rnn_time[best_model_rnn]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
