{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26958f22e50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import datetime\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Input, LSTM\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Input, Convolution1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "import pickle\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_agg_data_items=pd.read_csv(\"items_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_agg_data_items.drop(\"date\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(final_agg_data_items['unit_sales'].values.astype(np.float32))\n",
    "X = torch.tensor(final_agg_data_items.drop('unit_sales', axis = 1).values.astype(np.float32)) \n",
    "dataset = TensorDataset(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(dataset, [37817, 9455])\n",
    "train_loader1 = DataLoader(dataset = train_set, shuffle = True,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loader1=DataLoader(dataset = val_set, shuffle = True,batch_size=9455)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in validation_loader1:\n",
    "    X_test1,y_test1=i,j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(final_agg_data_items['unit_sales'].values.astype(np.float32))[:4500]\n",
    "X = torch.tensor(final_agg_data_items.drop('unit_sales', axis = 1).values.astype(np.float32))[:4500] \n",
    "dataset = TensorDataset(X,y) \n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [4000, 500])\n",
    "train_loader1 = DataLoader(dataset = train_set, shuffle = True,batch_size=16)\n",
    "\n",
    "validation_loader1=DataLoader(dataset = val_set, shuffle = True,batch_size=500)\n",
    "\n",
    "for i,j in validation_loader1:\n",
    "    X_test1,y_test1=i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstNetwork_v1(nn.Module):\n",
    "    def __init__(self,number_of_nodes):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(59,number_of_nodes)\n",
    "        self.lin2 = nn.Linear(number_of_nodes, 1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        a1 = self.lin1(X)\n",
    "        h1 = a1.relu()\n",
    "        a2 = self.lin2(h1)\n",
    "        return a2,a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_train_loss={}\n",
    "all_models_val_loss={}\n",
    "all_models_time={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model with 8  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 12  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 16  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 20  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 24  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 28  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 32  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n"
     ]
    }
   ],
   "source": [
    "for i in range(8,33,4):\n",
    "    print(\"Running Model with \"+str(i),\" nodes\")\n",
    "    all_models_train_loss[i]=[]\n",
    "    all_models_val_loss[i]=[] \n",
    "    all_models_time[i]=[]\n",
    "    for p in range(10):\n",
    "        #torch.manual_seed(np.random.randint(0,1000000,1))\n",
    "        for c,v in validation_loader1:\n",
    "            X_test1,y_test1=c,v\n",
    "        print(str(p)+\" Times Model Repeated\")\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        model1=FirstNetwork_v1(number_of_nodes=i).to(device)\n",
    "        criterion1 = nn.MSELoss()\n",
    "        training_loss_model1=[]\n",
    "        validation_loss_model1=[]\n",
    "        time_model1=[]\n",
    "        epochs = 100\n",
    "        optimizer1 = optim.SGD(model1.parameters(), lr=0.01)\n",
    "        for epoch in range(epochs):\n",
    "            training_loss_batch=[]\n",
    "            validation_loss_batch=[]\n",
    "            time_batch=[]\n",
    "            for X_train, y_train in train_loader1:\n",
    "                model1.train()\n",
    "                optimizer1.zero_grad()\n",
    "                X_train,y_train=X_train.to(device),y_train.to(device)\n",
    "                start.record()\n",
    "                output,features = model1(X_train)\n",
    "                loss1 = criterion1(output, y_train.reshape(-1,1))\n",
    "                loss1.backward()\n",
    "                optimizer1.step()\n",
    "                end.record()\n",
    "                training_loss_batch.append(loss1.item())\n",
    "                model1.eval()\n",
    "                validation_loss_batch.append(criterion1(model1(X_test1.to(device))[0],y_test1.to(device).reshape(-1,1)).item())\n",
    "                time_batch.append(start.elapsed_time(end))\n",
    "            training_loss_model1.append(training_loss_batch)\n",
    "            validation_loss_model1.append(validation_loss_batch)\n",
    "            time_model1.append(time_batch)\n",
    "        del model1\n",
    "        torch.cuda.empty_cache()\n",
    "        all_models_val_loss[i].append(validation_loss_model1)\n",
    "        all_models_train_loss[i].append(training_loss_model1)\n",
    "        all_models_time[i].append(time_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('item_model_train_sub.p', 'wb') as fp:\n",
    "    pickle.dump(all_models_train_loss, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('item_model_val_sub.p', 'wb') as fp:\n",
    "    pickle.dump(all_models_val_loss, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('item_model_time_sub.p', 'wb') as fp:\n",
    "    pickle.dump(all_models_time, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(r\"item_model_val_sub.p\", \"rb\") as input_file:\n",
    "    all_models_val_loss = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.0005636522839777172 4.154376562559264e-05\n",
      "12 0.000564779820269905 2.459806310151693e-05\n",
      "16 0.0005546936318743974 2.7671367566544387e-05\n",
      "20 0.0005635536837857217 2.7488227934772187e-05\n",
      "24 0.0005479372494039126 3.9935157810707905e-05\n",
      "28 0.0005548996355151757 3.36004235106098e-05\n",
      "32 0.0005520467435242609 2.2747787023011585e-05\n"
     ]
    }
   ],
   "source": [
    "for m in sorted(all_models_val_loss.keys()):\n",
    "    print(m,np.mean([min([np.mean(all_models_val_loss[m][k][i]) for i in range(len(all_models_val_loss[m][k]))]) for k in range(len(all_models_val_loss[m]))]),\n",
    "         np.std([min([np.mean(all_models_val_loss[m][k][i]) for i in range(len(all_models_val_loss[m][k]))]) for k in range(len(all_models_val_loss[m]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_train_loss={}\n",
    "all_models_val_loss={}\n",
    "all_models_time={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model with 8  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 12  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 16  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 20  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 24  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 28  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 32  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n"
     ]
    }
   ],
   "source": [
    "for i in range(8,33,4):\n",
    "    print(\"Running Model with \"+str(i),\" nodes\")\n",
    "    all_models_train_loss[i]=[]\n",
    "    all_models_val_loss[i]=[] \n",
    "    all_models_time[i]=[]\n",
    "    for p in range(10):\n",
    "        #torch.manual_seed(np.random.randint(0,1000000,1))\n",
    "        for c,v in validation_loader1:\n",
    "            X_test1,y_test1=c,v\n",
    "        print(str(p)+\" Times Model Repeated\")\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        model1=FirstNetwork_v1(number_of_nodes=i).to(device)\n",
    "        criterion1 = nn.MSELoss()\n",
    "        training_loss_model1=[]\n",
    "        validation_loss_model1=[]\n",
    "        time_model1=[]\n",
    "        epochs = 100\n",
    "        optimizer1 = optim.Adam(model1.parameters(), lr=0.01)\n",
    "        for epoch in range(epochs):\n",
    "            training_loss_batch=[]\n",
    "            validation_loss_batch=[]\n",
    "            time_batch=[]\n",
    "            for X_train, y_train in train_loader1:\n",
    "                model1.train()\n",
    "                optimizer1.zero_grad()\n",
    "                X_train,y_train=X_train.to(device),y_train.to(device)\n",
    "                start.record()\n",
    "                output,features = model1(X_train)\n",
    "                loss1 = criterion1(output, y_train.reshape(-1,1))\n",
    "                loss1.backward()\n",
    "                optimizer1.step()\n",
    "                end.record()\n",
    "                training_loss_batch.append(loss1.item())\n",
    "                model1.eval()\n",
    "                validation_loss_batch.append(criterion1(model1(X_test1.to(device))[0],y_test1.to(device).reshape(-1,1)).item())\n",
    "                time_batch.append(start.elapsed_time(end))\n",
    "            training_loss_model1.append(training_loss_batch)\n",
    "            validation_loss_model1.append(validation_loss_batch)\n",
    "            time_model1.append(time_batch)\n",
    "        del model1\n",
    "        torch.cuda.empty_cache()\n",
    "        all_models_val_loss[i].append(validation_loss_model1)\n",
    "        all_models_train_loss[i].append(training_loss_model1)\n",
    "        all_models_time[i].append(time_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('item_model_train_sub1.p', 'wb') as fp:\n",
    "    pickle.dump(all_models_train_loss, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('item_model_val_sub1.p', 'wb') as fp:\n",
    "    pickle.dump(all_models_val_loss, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('item_model_time_sub1.p', 'wb') as fp:\n",
    "    pickle.dump(all_models_time, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.0003920391722465865 2.0395308715456865e-05\n",
      "12 0.00040141523979837074 1.4180715352374758e-05\n",
      "16 0.0004129926721798256 1.548025645480361e-05\n",
      "20 0.0004147644046111963 1.2750763227951032e-05\n",
      "24 0.00040376113220117984 1.1526223251039313e-05\n",
      "28 0.00041906523117795594 1.0984285360889566e-05\n",
      "32 0.00041761934232199566 1.0346181320166081e-05\n"
     ]
    }
   ],
   "source": [
    "for m in sorted(all_models_val_loss.keys()):\n",
    "    print(m,np.mean([min([np.mean(all_models_val_loss[m][k][i]) for i in range(len(all_models_val_loss[m][k]))]) for k in range(len(all_models_val_loss[m]))]),\n",
    "         np.std([min([np.mean(all_models_val_loss[m][k][i]) for i in range(len(all_models_val_loss[m][k]))]) for k in range(len(all_models_val_loss[m]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(final_agg_data_items['unit_sales'].values.astype(np.float32))[:4500]\n",
    "X = torch.tensor(final_agg_data_items.drop('unit_sales', axis = 1).values.astype(np.float32))[:4500] \n",
    "dataset = TensorDataset(X,y) \n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [4000, 500])\n",
    "train_loader1 = DataLoader(dataset = train_set, shuffle = True,batch_size=32)\n",
    "\n",
    "validation_loader1=DataLoader(dataset = val_set, shuffle = True,batch_size=500)\n",
    "\n",
    "for i,j in validation_loader1:\n",
    "    X_test1,y_test1=i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_train_loss={}\n",
    "all_models_val_loss={}\n",
    "all_models_time={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model with 8  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 12  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 16  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 20  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 24  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 28  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n",
      "Running Model with 32  nodes\n",
      "0 Times Model Repeated\n",
      "1 Times Model Repeated\n",
      "2 Times Model Repeated\n",
      "3 Times Model Repeated\n",
      "4 Times Model Repeated\n",
      "5 Times Model Repeated\n",
      "6 Times Model Repeated\n",
      "7 Times Model Repeated\n",
      "8 Times Model Repeated\n",
      "9 Times Model Repeated\n"
     ]
    }
   ],
   "source": [
    "for i in range(8,33,4):\n",
    "    print(\"Running Model with \"+str(i),\" nodes\")\n",
    "    all_models_train_loss[i]=[]\n",
    "    all_models_val_loss[i]=[] \n",
    "    all_models_time[i]=[]\n",
    "    for p in range(10):\n",
    "        #torch.manual_seed(np.random.randint(0,1000000,1))\n",
    "        for c,v in validation_loader1:\n",
    "            X_test1,y_test1=c,v\n",
    "        print(str(p)+\" Times Model Repeated\")\n",
    "        start = torch.cuda.Event(enable_timing=True)\n",
    "        end = torch.cuda.Event(enable_timing=True)\n",
    "        model1=FirstNetwork_v1(number_of_nodes=i).to(device)\n",
    "        criterion1 = nn.MSELoss()\n",
    "        training_loss_model1=[]\n",
    "        validation_loss_model1=[]\n",
    "        time_model1=[]\n",
    "        epochs = 100\n",
    "        optimizer1 = optim.Adam(model1.parameters(), lr=0.01)\n",
    "        for epoch in range(epochs):\n",
    "            training_loss_batch=[]\n",
    "            validation_loss_batch=[]\n",
    "            time_batch=[]\n",
    "            for X_train, y_train in train_loader1:\n",
    "                model1.train()\n",
    "                optimizer1.zero_grad()\n",
    "                X_train,y_train=X_train.to(device),y_train.to(device)\n",
    "                start.record()\n",
    "                output,features = model1(X_train)\n",
    "                loss1 = criterion1(output, y_train.reshape(-1,1))\n",
    "                loss1.backward()\n",
    "                optimizer1.step()\n",
    "                end.record()\n",
    "                training_loss_batch.append(loss1.item())\n",
    "                model1.eval()\n",
    "                validation_loss_batch.append(criterion1(model1(X_test1.to(device))[0],y_test1.to(device).reshape(-1,1)).item())\n",
    "                time_batch.append(start.elapsed_time(end))\n",
    "            training_loss_model1.append(training_loss_batch)\n",
    "            validation_loss_model1.append(validation_loss_batch)\n",
    "            time_model1.append(time_batch)\n",
    "        del model1\n",
    "        torch.cuda.empty_cache()\n",
    "        all_models_val_loss[i].append(validation_loss_model1)\n",
    "        all_models_train_loss[i].append(training_loss_model1)\n",
    "        all_models_time[i].append(time_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('item_model_train_sub2.p', 'wb') as fp:\n",
    "    pickle.dump(all_models_train_loss, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('item_model_val_sub2.p', 'wb') as fp:\n",
    "    pickle.dump(all_models_val_loss, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('item_model_time_sub2.p', 'wb') as fp:\n",
    "    pickle.dump(all_models_time, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.00033825696867424997 1.8859174560056575e-05\n",
      "12 0.00033522513252682987 1.4521382213293949e-05\n",
      "16 0.00032762858977075665 1.3019008436754745e-05\n",
      "20 0.00034038469686638567 1.2291623537315578e-05\n",
      "24 0.0003293667370453477 1.2302603371162126e-05\n",
      "28 0.00034147421498782933 1.5023899176377172e-05\n",
      "32 0.00034278636747039855 1.376327441764471e-05\n"
     ]
    }
   ],
   "source": [
    "for m in sorted(all_models_val_loss.keys()):\n",
    "    print(m,np.mean([min([np.mean(all_models_val_loss[m][k][i]) for i in range(len(all_models_val_loss[m][k]))]) for k in range(len(all_models_val_loss[m]))]),\n",
    "         np.std([min([np.mean(all_models_val_loss[m][k][i]) for i in range(len(all_models_val_loss[m][k]))]) for k in range(len(all_models_val_loss[m]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"item_model_val_sub.p\", \"rb\") as input_file:\n",
    "    all_models_val_loss= pickle.load(input_file)\n",
    "\n",
    "item_model_loss={}\n",
    "\n",
    "for m in sorted(all_models_val_loss.keys()):\n",
    "        item_model_loss[m]=[min([np.mean(all_models_val_loss[m][k][i]) for i in range(len(all_models_val_loss[m][k]))]) for k in range(len(all_models_val_loss[m]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"item_model_val_sub1.p\", \"rb\") as input_file:\n",
    "    all_models_val_loss= pickle.load(input_file)\n",
    "\n",
    "item_model_loss1={}\n",
    "\n",
    "for m in sorted(all_models_val_loss.keys()):\n",
    "        item_model_loss1[m]=[min([np.mean(all_models_val_loss[m][k][i]) for i in range(len(all_models_val_loss[m][k]))]) for k in range(len(all_models_val_loss[m]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"item_model_time_sub2.p\", \"rb\") as input_file:\n",
    "    all_models_val_loss= pickle.load(input_file)\n",
    "\n",
    "item_model_loss2={}\n",
    "\n",
    "for m in sorted(all_models_val_loss.keys()):\n",
    "        item_model_loss2[m]=[min([np.mean(all_models_val_loss[m][k][i]) for i in range(len(all_models_val_loss[m][k]))]) for k in range(len(all_models_val_loss[m]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2694eca7668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(20,8),sharey=True)\n",
    "ax[0].boxplot(item_model_loss.values(),labels=item_model_loss.keys())\n",
    "ax[1].boxplot(item_model_loss1.values(),labels=item_model_loss1.keys())\n",
    "ax[2].boxplot(item_model_loss2.values(),labels=item_model_loss2.keys())\n",
    "ax[0].set_ylabel(\"Mean Squared Error\")\n",
    "ax[0].set_xlabel(\"Stochastic Gradient Descent(Batch Size 16)\")\n",
    "ax[1].set_xlabel(\"Adam Optimizer(Batch Size 16)\")\n",
    "ax[2].set_xlabel(\"Adam Optimizer(Batch Size 32)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"item_model_val_sub1.p\", \"rb\") as input_file:\n",
    "    all_models_val_loss_p= pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list=[]\n",
    "for y in range(10):\n",
    "    min_arg=np.argmin([np.mean(all_models_val_loss_p[16][y][i]) for i in range(len(all_models_val_loss_p[16][y]))])\n",
    "    time_list.append(np.cumsum([sum(all_models_val_loss[16][y][i]) for i in range(len(all_models_val_loss[16][y]))][:min_arg])[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28403.851563620567"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(time_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(final_agg_data_items['unit_sales'].values.astype(np.float32))\n",
    "X = torch.tensor(final_agg_data_items.drop('unit_sales', axis = 1).values.astype(np.float32)) \n",
    "dataset = TensorDataset(X,y) \n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [37817, 9455])\n",
    "train_loader1 = DataLoader(dataset = train_set, shuffle = True,batch_size=32)\n",
    "\n",
    "validation_loader1=DataLoader(dataset = val_set, shuffle = True,batch_size=9455)\n",
    "\n",
    "for i,j in validation_loader1:\n",
    "    X_test1,y_test1=i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstNetwork_final(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.lin1 = nn.Linear(59,16)\n",
    "        self.lin2 = nn.Linear(16, 1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        a1 = self.lin1(X)\n",
    "        h1 = a1.relu()\n",
    "        a2 = self.lin2(h1)\n",
    "        return a2,a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=FirstNetwork_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training Loss: 0.0004192280644496836\n",
      "Validation Loss: 0.0003552512594477223\n",
      "10\n",
      "Training Loss: 0.0002494790591755051\n",
      "Validation Loss: 0.00021582225935656558\n",
      "20\n",
      "Training Loss: 0.0002544169708983287\n",
      "Validation Loss: 0.00022931470001485142\n",
      "30\n",
      "Training Loss: 0.0002698412232816174\n",
      "Validation Loss: 0.0002281149790103054\n"
     ]
    }
   ],
   "source": [
    "criterion1 = nn.MSELoss()\n",
    "\n",
    "training_loss_model1=[]\n",
    "validation_loss_model1=[]\n",
    "\n",
    "epochs = 40\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    training_loss_batch=[]\n",
    "    validation_loss_batch=[]\n",
    "    for X_train, y_train in train_loader1:\n",
    "        optimizer1.zero_grad()\n",
    "        output,features = model1(X_train)\n",
    "        loss1= criterion1(output, y_train.reshape(-1,1))\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        training_loss_batch.append(loss1.item())\n",
    "        validation_loss_batch.append(criterion1(model1(X_test1)[0],y_test1.reshape(-1,1)).item())\n",
    "    validation_loss_model1.append(validation_loss_batch)\n",
    "    training_loss_model1.append(training_loss_batch)\n",
    "    if epoch%10==0:\n",
    "        print(epoch)\n",
    "        print(\"Training Loss:\",np.mean(training_loss_batch))\n",
    "        print(\"Validation Loss:\",np.mean(validation_loss_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "Training Loss: 0.00026867224403515734\n",
      "Validation Loss: 0.00023864384614720677\n",
      "50\n",
      "Training Loss: 0.0002611137959723525\n",
      "Validation Loss: 0.00023553600391641326\n",
      "60\n",
      "Training Loss: 0.00027825560244989795\n",
      "Validation Loss: 0.0002473072876479885\n",
      "70\n",
      "Training Loss: 0.0002742458388227736\n",
      "Validation Loss: 0.00024237371366319377\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(40,80):\n",
    "    training_loss_batch=[]\n",
    "    validation_loss_batch=[]\n",
    "    for X_train, y_train in train_loader1:\n",
    "        optimizer1.zero_grad()\n",
    "        output,features = model1(X_train)\n",
    "        loss1= criterion1(output, y_train.reshape(-1,1))\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        training_loss_batch.append(loss1.item())\n",
    "        validation_loss_batch.append(criterion1(model1(X_test1)[0],y_test1.reshape(-1,1)).item())\n",
    "    validation_loss_model1.append(validation_loss_batch)\n",
    "    training_loss_model1.append(training_loss_batch)\n",
    "    if epoch%10==0:\n",
    "        print(epoch)\n",
    "        print(\"Training Loss:\",np.mean(training_loss_batch))\n",
    "        print(\"Validation Loss:\",np.mean(validation_loss_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "Training Loss: 0.0002327643268704832\n",
      "Validation Loss: 0.00020269614195184428\n",
      "90\n",
      "Training Loss: 0.00022921912926474687\n",
      "Validation Loss: 0.00019655229317982857\n",
      "100\n",
      "Training Loss: 0.00023006050573305044\n",
      "Validation Loss: 0.00019810156316702078\n",
      "110\n",
      "Training Loss: 0.00022918316816856365\n",
      "Validation Loss: 0.00019713200570599062\n"
     ]
    }
   ],
   "source": [
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "for epoch in range(80,120):\n",
    "    training_loss_batch=[]\n",
    "    validation_loss_batch=[]\n",
    "    for X_train, y_train in train_loader1:\n",
    "        optimizer1.zero_grad()\n",
    "        output,features = model1(X_train)\n",
    "        loss1= criterion1(output, y_train.reshape(-1,1))\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        training_loss_batch.append(loss1.item())\n",
    "        validation_loss_batch.append(criterion1(model1(X_test1)[0],y_test1.reshape(-1,1)).item())\n",
    "    validation_loss_model1.append(validation_loss_batch)\n",
    "    training_loss_model1.append(training_loss_batch)\n",
    "    if epoch%10==0:\n",
    "        print(epoch)\n",
    "        print(\"Training Loss:\",np.mean(training_loss_batch))\n",
    "        print(\"Validation Loss:\",np.mean(validation_loss_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "Training Loss: 0.0002288852740606173\n",
      "Validation Loss: 0.0001956799971622292\n",
      "130\n",
      "Training Loss: 0.00022952499704893706\n",
      "Validation Loss: 0.0001964997159036045\n",
      "140\n",
      "Training Loss: 0.00022873267439108946\n",
      "Validation Loss: 0.000196079515254987\n",
      "150\n",
      "Training Loss: 0.00022866616765238629\n",
      "Validation Loss: 0.00019667682636512662\n"
     ]
    }
   ],
   "source": [
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "for epoch in range(120,160):\n",
    "    training_loss_batch=[]\n",
    "    validation_loss_batch=[]\n",
    "    for X_train, y_train in train_loader1:\n",
    "        optimizer1.zero_grad()\n",
    "        output,features = model1(X_train)\n",
    "        loss1= criterion1(output, y_train.reshape(-1,1))\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        training_loss_batch.append(loss1.item())\n",
    "        validation_loss_batch.append(criterion1(model1(X_test1)[0],y_test1.reshape(-1,1)).item())\n",
    "    validation_loss_model1.append(validation_loss_batch)\n",
    "    training_loss_model1.append(training_loss_batch)\n",
    "    if epoch%10==0:\n",
    "        print(epoch)\n",
    "        print(\"Training Loss:\",np.mean(training_loss_batch))\n",
    "        print(\"Validation Loss:\",np.mean(validation_loss_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "Training Loss: 0.00022449658524538603\n",
      "Validation Loss: 0.0001919164319780526\n",
      "170\n",
      "Training Loss: 0.00022382415581498897\n",
      "Validation Loss: 0.00019153068674367406\n",
      "180\n",
      "Training Loss: 0.00022375873782185177\n",
      "Validation Loss: 0.00019171667716059323\n",
      "190\n",
      "Training Loss: 0.00022388341147291254\n",
      "Validation Loss: 0.00019146908469464276\n"
     ]
    }
   ],
   "source": [
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.0001)\n",
    "for epoch in range(160,200):\n",
    "    training_loss_batch=[]\n",
    "    validation_loss_batch=[]\n",
    "    for X_train, y_train in train_loader1:\n",
    "        optimizer1.zero_grad()\n",
    "        output,features = model1(X_train)\n",
    "        loss1= criterion1(output, y_train.reshape(-1,1))\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        training_loss_batch.append(loss1.item())\n",
    "        validation_loss_batch.append(criterion1(model1(X_test1)[0],y_test1.reshape(-1,1)).item())\n",
    "    validation_loss_model1.append(validation_loss_batch)\n",
    "    training_loss_model1.append(training_loss_batch)\n",
    "    if epoch%10==0:\n",
    "        print(epoch)\n",
    "        print(\"Training Loss:\",np.mean(training_loss_batch))\n",
    "        print(\"Validation Loss:\",np.mean(validation_loss_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Training Loss: 0.00022393588710617858\n",
      "Validation Loss: 0.0001914098133404334\n",
      "210\n",
      "Training Loss: 0.00022405110575323423\n",
      "Validation Loss: 0.00019146792121854406\n",
      "220\n",
      "Training Loss: 0.00022393179557959948\n",
      "Validation Loss: 0.00019145374093116095\n",
      "230\n",
      "Training Loss: 0.00022387686475923037\n",
      "Validation Loss: 0.00019147425301293424\n"
     ]
    }
   ],
   "source": [
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.0001)\n",
    "for epoch in range(200,240):\n",
    "    training_loss_batch=[]\n",
    "    validation_loss_batch=[]\n",
    "    for X_train, y_train in train_loader1:\n",
    "        optimizer1.zero_grad()\n",
    "        output,features = model1(X_train)\n",
    "        loss1= criterion1(output, y_train.reshape(-1,1))\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        training_loss_batch.append(loss1.item())\n",
    "        validation_loss_batch.append(criterion1(model1(X_test1)[0],y_test1.reshape(-1,1)).item())\n",
    "    validation_loss_model1.append(validation_loss_batch)\n",
    "    training_loss_model1.append(training_loss_batch)\n",
    "    if epoch%10==0:\n",
    "        print(epoch)\n",
    "        print(\"Training Loss:\",np.mean(training_loss_batch))\n",
    "        print(\"Validation Loss:\",np.mean(validation_loss_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1.state_dict(), \"items_model_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
