{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import datetime\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Input, LSTM\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Input, Convolution1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn as nn\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"agg_final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data[\"unit_sales\"]=scaler.fit_transform(np.array(data.unit_sales).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data=pd.read_csv(\"stores_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data=pd.read_csv(\"items_agg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stores_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[i for i in store_data.columns if \"store\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.sort(key=natural_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array(store_data[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data[\"store_nbr\"]=[np.where(r==1)[0][0]+1 for r in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.tensor(store_data[['store_nbr_1', 'store_nbr_10', 'store_nbr_11', 'store_nbr_12',\n",
    "       'store_nbr_13', 'store_nbr_14', 'store_nbr_15', 'store_nbr_16',\n",
    "       'store_nbr_17', 'store_nbr_18', 'store_nbr_19', 'store_nbr_2',\n",
    "       'store_nbr_20', 'store_nbr_21', 'store_nbr_22', 'store_nbr_23',\n",
    "       'store_nbr_24', 'store_nbr_25', 'store_nbr_26', 'store_nbr_27',\n",
    "       'store_nbr_28', 'store_nbr_29', 'store_nbr_3', 'store_nbr_30',\n",
    "       'store_nbr_31', 'store_nbr_32', 'store_nbr_33', 'store_nbr_34',\n",
    "       'store_nbr_35', 'store_nbr_36', 'store_nbr_37', 'store_nbr_38',\n",
    "       'store_nbr_39', 'store_nbr_4', 'store_nbr_40', 'store_nbr_41',\n",
    "       'store_nbr_42', 'store_nbr_43', 'store_nbr_44', 'store_nbr_45',\n",
    "       'store_nbr_46', 'store_nbr_47', 'store_nbr_48', 'store_nbr_49',\n",
    "       'store_nbr_5', 'store_nbr_50', 'store_nbr_51', 'store_nbr_52',\n",
    "       'store_nbr_53', 'store_nbr_54', 'store_nbr_6', 'store_nbr_7',\n",
    "       'store_nbr_8', 'store_nbr_9', 'region_Amazon', 'region_Coast',\n",
    "       'region_Sierra', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3',\n",
    "       'weekday_4', 'weekday_5', 'weekday_6', 'month_1', 'month_10',\n",
    "       'month_11', 'month_12', 'month_2', 'month_3', 'month_4', 'month_5',\n",
    "       'month_6', 'month_7', 'month_8', 'month_9',\n",
    "       't1', 't2', 't3', 't4', 't5', 't6', 't7']].values.astype(np.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data_loader=DataLoader(dataset =X1, shuffle = False,batch_size=83110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in store_data_loader:\n",
    "    X_test=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstNetwork_v1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.lin1 = nn.Linear(83,25)\n",
    "        self.lin2 = nn.Linear(25, 1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        a1 = self.lin1(X) #computes the dot product and adds bias\n",
    "        h1 = a1.relu()\n",
    "        a2 = self.lin2(h1) #computes dot product and adds bias\n",
    "        return a2,a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_model = FirstNetwork_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FirstNetwork_v1(\n",
       "  (lin1): Linear(in_features=83, out_features=25, bias=True)\n",
       "  (lin2): Linear(in_features=25, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_model.load_state_dict(torch.load(\"stores_model_final.pt\"))\n",
    "stores_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output,store_features=stores_model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data[[\"store_features_\"+str(i) for i in range(1,26)]]=pd.DataFrame(store_features.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store_feature_combined=store_data[['date','store_nbr', 'store_features_1', 'store_features_2',\n",
    "       'store_features_3', 'store_features_4', 'store_features_5',\n",
    "       'store_features_6', 'store_features_7', 'store_features_8',\n",
    "       'store_features_9', 'store_features_10', 'store_features_11',\n",
    "       'store_features_12', 'store_features_13', 'store_features_14',\n",
    "       'store_features_15', 'store_features_16', 'store_features_17',\n",
    "       'store_features_18', 'store_features_19', 'store_features_20','store_features_21',\n",
    "                                   'store_features_22','store_features_23','store_features_24','store_features_25']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[i for i in item_data.columns if \"family\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=np.array(item_data[m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data[\"family\"]=[np.where(r==1)[0][0]+1 for r in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data[\"family\"]=item_data.family.map(dict(zip(np.arange(1,34),[i[7:] for i in m])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.tensor(item_data[['family_AUTOMOTIVE', 'family_BABY CARE', 'family_BEAUTY',\n",
    "       'family_BEVERAGES', 'family_BOOKS', 'family_BREAD/BAKERY',\n",
    "       'family_CELEBRATION', 'family_CLEANING', 'family_DAIRY', 'family_DELI',\n",
    "       'family_EGGS', 'family_FROZEN FOODS', 'family_GROCERY I',\n",
    "       'family_GROCERY II', 'family_HARDWARE', 'family_HOME AND KITCHEN I',\n",
    "       'family_HOME AND KITCHEN II', 'family_HOME APPLIANCES',\n",
    "       'family_HOME CARE', 'family_LADIESWEAR', 'family_LAWN AND GARDEN',\n",
    "       'family_LINGERIE', 'family_LIQUOR,WINE,BEER', 'family_MAGAZINES',\n",
    "       'family_MEATS', 'family_PERSONAL CARE', 'family_PET SUPPLIES',\n",
    "       'family_PLAYERS AND ELECTRONICS', 'family_POULTRY',\n",
    "       'family_PREPARED FOODS', 'family_PRODUCE',\n",
    "       'family_SCHOOL AND OFFICE SUPPLIES', 'family_SEAFOOD', 'weekday_0',\n",
    "       'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5',\n",
    "       'weekday_6', 'month_1', 'month_10', 'month_11', 'month_12', 'month_2',\n",
    "       'month_3', 'month_4', 'month_5', 'month_6', 'month_7', 'month_8',\n",
    "       'month_9', 't1', 't2', 't3', 't4', 't5', 't6', 't7',]].values.astype(np.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data_loader=DataLoader(dataset =X1, shuffle = False,batch_size=len(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in item_data_loader:\n",
    "    X_test=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecondNetwork_v1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.lin1 = nn.Linear(59,16)\n",
    "        self.lin2 = nn.Linear(16, 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        a1 = self.lin1(X)\n",
    "        h1 = a1.relu()\n",
    "        a2 = self.lin2(h1)\n",
    "        return a2,a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_model=SecondNetwork_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SecondNetwork_v1(\n",
       "  (lin1): Linear(in_features=59, out_features=16, bias=True)\n",
       "  (lin2): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_model.load_state_dict(torch.load(\"items_model_final.pt\"))\n",
    "items_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,items_features=items_model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data[[\"item_features_\"+str(i) for i in range(1,17)]]=pd.DataFrame(items_features.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_feature_combined=item_data[[\"date\",'family', 'item_features_1', 'item_features_2',\n",
    "       'item_features_3', 'item_features_4', 'item_features_5',\n",
    "       'item_features_6', 'item_features_7', 'item_features_8',\n",
    "       'item_features_9', 'item_features_10', 'item_features_11',\n",
    "       'item_features_12', 'item_features_13', 'item_features_14',\n",
    "       'item_features_15', 'item_features_16']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=data[[\"date\",\"store_nbr\",\"family\",\"unit_sales\"]].merge(store_feature_combined,on=[\"date\",\"store_nbr\"],\n",
    "                                          how=\"left\").merge(item_feature_combined,on=[\"date\",\"family\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.dropna(axis=0,how=\"any\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.drop([\"date\",\"store_nbr\",\"family\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(\"final_data.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
